# -*- coding: utf-8 -*-
"""fasttext_dop1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZAUbgmmQLuLhI8P4bR8xR0FqhuiDrBaG
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload

from gensim.models import Word2Vec, KeyedVectors

import pandas as pd
import numpy as np

table = pd.read_csv('quora_question_pairs_rus.csv')

test_N = 500

test_table = table.head(test_N)

texts = []
for row in test_table['question2']:
    texts.append(str(row))

queries = []
for row in test_table['question1']:
    queries.append(str(row))

import pymorphy2
morph = pymorphy2.MorphAnalyzer()

import re
def tokenize(line): #функция возвращает список токенов данного предложения
    ws = []
    words = line.split()
    for w in words:
        w = re.sub('[.,-;:?!@#$%^&()_+=—–"…}{/\|«»>]', '', w).lower()
        if w != "":
            p = morph.parse(w)[0]
            ws.append(p.normal_form)
    return ws

# если модель без тэгов
model_file = 'model.model'

#model = Word2Vec.load(model_file)

model = KeyedVectors.load(model_file)

def doc_vector(doc):
    lemmas = tokenize(doc)
  
    lemmas_vectors = np.zeros((len(lemmas), model.vector_size))
    doc_vec = np.zeros((model.vector_size,))
  
    for idx, lemma in enumerate(lemmas):
        if lemma in model.vocab:
            try:
                lemmas_vectors[idx] = model[lemma]
            except AttributeError as err:
                print(err)
    if lemmas_vectors.shape[0] is not 0:
        doc_vec = np.mean(lemmas_vectors, axis=0)
        return doc_vec

vecs = []
for i in texts:
    res = doc_vector(i)
    vecs.append(res)

def search_fasttext(query):
    query_vec = doc_vector(query)
    cos_sims = []
    for doc in vecs:
        res = np.inner(query_vec, doc)/(np.linalg.norm(query_vec)*np.linalg.norm(doc))
        cos_sims.append(res)
    ids = []
    for x in sorted(enumerate(cos_sims), key=lambda x:x[1], reverse=True):
        ids.append(x[0])
    top_n = ids[:5]
    results = []
    for i in top_n:
        results.append([cos_sims[i], np.array(texts)[i]])
    return results
